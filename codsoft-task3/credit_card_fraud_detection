import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import accuracy_score, classification_report
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.utils import resample
import joblib
import os
from google.colab import files

# Upload dataset
uploaded = files.upload()

# Get the filename
filename = list(uploaded.keys())[0]

# Load dataset into DataFrame
df = pd.read_csv(filename)

# Print column names to confirm target column
print("Dataset Columns:", df.columns)

# Define target column
target_column = 'IsFraud'

# Drop irrelevant columns based on actual dataset (if they exist)
irrelevant_columns = ['TransactionID', 'TransactionDate', 'Location']
df = df.drop(columns=[col for col in irrelevant_columns if col in df.columns])

# Handle class imbalance by upsampling minority class
fraud = df[df[target_column] == 1]
non_fraud = df[df[target_column] == 0]
fraud_upsampled = resample(fraud, replace=True, n_samples=len(non_fraud), random_state=42)
df_balanced = pd.concat([non_fraud, fraud_upsampled])

# Splitting data into features and target
X = df_balanced.drop(columns=[target_column])
y = df_balanced[target_column]

# Separate categorical and numeric features
categorical_features = ['MerchantID', 'TransactionType']
numeric_features = ['Amount']

# Preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])

# Model pipeline with RandomForestClassifier
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced'))
])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Train model
pipeline.fit(X_train, y_train)

# Evaluate the model
y_pred = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Model Accuracy: {accuracy:.4f}')
print(classification_report(y_test, y_pred))

# Save model
model_path = "fraud_detection_model.pkl"
joblib.dump(pipeline, model_path)

# Download the model
files.download(model_path)

# Print Kaggle output command
print("kaggle kernels output janasruthin/FRAUD_DETECTION/kaggle/working/")
